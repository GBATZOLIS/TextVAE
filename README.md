# Textâ€‘VAE with Diffusion Decoder

A modular PyTorch implementation of a Variational Auto-Encoder (VAE) that:

- Encodes images into a discrete latent space using a Gumbel-Softmax bottleneck.
- Decodes latents into text via an autoregressive Transformer.
- Reconstructs images from text using a DDPM-based diffusion model.

---

## ğŸ§± Project Structure

```

text\_vae\_project/
â”œâ”€â”€ config.py               # Configuration dataclass
â”œâ”€â”€ datasets.py             # Dummy dataset loader
â”œâ”€â”€ trainer.py              # Training loop
â”œâ”€â”€ main.py                 # Entry-point script
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ models/
â”œâ”€â”€ **init**.py
â”œâ”€â”€ gumbel\_softmax.py
â”œâ”€â”€ vision\_encoder.py
â”œâ”€â”€ text\_decoder.py
â”œâ”€â”€ vae.py
â””â”€â”€ diffusion/
â”œâ”€â”€ **init**.py
â”œâ”€â”€ unet.py
â””â”€â”€ diffusion\_decoder.py

````

---

## ğŸš€ Getting Started

### 1. Clone and install dependencies

```bash
git clone https://github.com/your-username/text-vae-diffusion.git
cd text-vae-diffusion
pip install -r requirements.txt
````

### 2. Run training (example)

```bash
python main.py --epochs 10 --batch 8
```

---

## ğŸ§ª Notes

* The text decoder uses GPT-2 embeddings and can optionally freeze the language model.
* Gumbel-Softmax annealing is supported for hard/soft token sampling.
* The image reconstruction is performed via a UNet-based DDPM.

---

## âœï¸ TODO

* Replace `DummyImageDataset` with real data (e.g. ImageNet, CelebA).
* Add evaluation/metrics (e.g., FID for images, BLEU for text).
* Support for conditional generation and guided sampling.

---

## ğŸ“œ License

MIT License

---

## ğŸ™‹â€â™‚ï¸ Need Help?

Let me know if you'd like:

* ğŸ§ª A Colab notebook example
* âš™ï¸ GitHub Actions CI/CD config
* ğŸ’¾ Model checkpoints or ğŸ¤— Hugging Face integration

