# Textâ€‘VAE with Diffusion Decoder

## ğŸ§± Project Structure

```

TextVAE/
â”œâ”€â”€ config.py               # Configuration dataclass
â”œâ”€â”€ datasets.py            # Dummy dataset loader
â”œâ”€â”€ main.py                # Entry-point script
â”œâ”€â”€ trainer.py             # Training loop
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ models/
â”œâ”€â”€ init.py
â”œâ”€â”€ gumbel_softmax.py
â”œâ”€â”€ vision_encoder.py
â”œâ”€â”€ text_decoder.py
â”œâ”€â”€ vae.py
â””â”€â”€ diffusion/
â”œâ”€â”€ init.py
â”œâ”€â”€ diffusion_decoder.py
â””â”€â”€ unet.py

````

---

## ğŸš€ Getting Started

### 1. Clone and install dependencies

```bash
git clone https://github.com/GBATZOLIS/TextVAE.git
cd TextVAE
pip install -r requirements.txt
````

### 2. Run training (example)

```bash
python main.py --epochs 10 --batch 8
```

---

## ğŸ§ª Notes

* The text decoder uses GPT-2 embeddings and can optionally freeze the language model.
* Gumbel-Softmax annealing is supported for hard/soft token sampling.
* The image reconstruction is performed via a UNet-based DDPM.

---

## âœï¸ TODO

* Replace `DummyImageDataset` with real data (e.g. ImageNet, CelebA).
* Add evaluation/metrics (e.g., FID for images, BLEU for text).

---


